{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87834266-3e9f-45f4-ab70-2550fee3fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: [13.00012571]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.seterr(invalid='ignore')\n",
    "\n",
    "\n",
    "#def negPoissontDist(n, lambda_val):\n",
    " #   return -np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n)\n",
    "\n",
    "#def maximize(n):\n",
    " #   result = scipy.optimize.minimize(negPoissontDist, x0=[10], args=(n,))\n",
    "  #return result\n",
    "\n",
    "\n",
    "#This function gives the probability of getting n counts for a given bin\n",
    "def poissant_distribution(n, lambda_val):\n",
    "    if n>=150:\n",
    "        return 0.0\n",
    "    return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
    "\n",
    "#This is just so we can use the minimize function from scipy\n",
    "def negative_probability_distribution(lambda_val, n):\n",
    "    return -poissant_distribution(n, lambda_val)\n",
    "\n",
    "#This will find the lambda that gives the highest probability of getting a given n, n would be our measured counts per bin\n",
    "def maximize_distribution(n):\n",
    "    result = scipy.optimize.minimize(negative_probability_distribution, x0=[10],bounds=[(0,None)], args=(n,))\n",
    "    return result.x\n",
    "\n",
    "fixed_n = 13\n",
    "\n",
    "optimal_lambda = maximize_distribution(fixed_n)\n",
    "print(f\"Lambda: {optimal_lambda}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3cb98c7-c7e0-4d81-8548-ed1429babf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time    blah\n",
      "9   506.1574  5.2894\n",
      "5   507.4013  5.9058\n",
      "8   509.4632  5.6750\n",
      "10  509.8995  5.2232\n",
      "13  510.0812  5.0349\n",
      "3   512.5145  6.3243\n",
      "19  512.7067  4.2205\n",
      "12  513.7324  5.0628\n",
      "14  513.8779  4.9122\n",
      "4   514.5219  6.1499\n",
      "[ 506.1574  507.4013  509.4632  509.8995  510.0812  512.5145  512.7067\n",
      "  513.7324  513.8779  514.5219  516.8201  517.7107  518.5185  519.2819\n",
      "  519.8351  524.4211  525.2859  525.2859  526.9375  528.7008  529.4175\n",
      "  530.1161  534.9125  535.2761  536.9121  537.7742  543.2328  550.717\n",
      "  551.226   553.132   553.3139  553.7683  554.0956  557.6922  558.5466\n",
      "  565.1764  566.9474  567.3552  571.5335  574.8757  576.3014  578.0828\n",
      "  578.1919  580.6901  583.0324  584.7126  587.0472  593.4147  593.986\n",
      "  594.7132  596.1207  602.9245  616.2568  616.7476  623.1592  623.5592\n",
      "  627.683   627.9011  637.3381  637.8289  638.3016  638.3275  648.4008\n",
      "  651.4703  651.517   652.3974  652.5064  660.6087  661.3799  661.4708\n",
      "  665.4129  670.0093  674.8498  676.0211  678.1193  680.363   683.178\n",
      "  687.8277  690.4077  690.9167  694.8951  696.8194  698.8008  709.4272\n",
      "  710.0634  712.5694  721.861   724.5773  725.0681  734.5129  735.8944\n",
      "  752.5689  753.0597  756.8927  768.5994  770.2354  772.0247  780.9254\n",
      "  784.5351  784.5403  784.626   788.0499  789.7717  790.3884  792.6737\n",
      "  794.7719  801.5653  804.2089  805.5385  807.7692  809.839   816.0662\n",
      "  823.4777  827.1703  830.1387  832.3434  832.5551  839.721   841.3675\n",
      "  847.8181  853.5546  853.9     860.0117  876.7835  884.5262  886.083\n",
      "  888.8162  894.0917  895.0175  895.4213  901.3032  919.145   924.2362\n",
      "  925.0892  930.8699  952.5186  953.6678  955.4336  958.5953  959.9665\n",
      "  966.047   966.8195  978.0692  981.1192  988.5463  993.1778  993.7711\n",
      "  997.9729 1008.572  1010.5846 1022.3913 1030.2712 1045.506  1046.2968\n",
      " 1046.7784 1066.0433 1071.4344 1076.9424 1087.1377 1095.6112 1109.2084\n",
      " 1110.499  1123.9365 1127.6812 1134.2124 1138.4453 1147.1006 1157.1271\n",
      " 1190.3904 1209.1268 1213.3129 1231.4962 1244.195  1263.1313 1268.3276\n",
      " 1276.3285 1279.7616 1298.9628 1298.9991 1324.7574 1341.9045 1348.0826\n",
      " 1360.0256 1376.1833 1383.8856 1399.0356 1416.2997 1421.1974 1431.6056]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "\n",
    "#importing and sorting data\n",
    "ge_data = pds.read_csv(\"SuperCDMS/PhysRevD.99.062001-data/MarchAprilFinal.txt\", skiprows=1, \\\n",
    "                         names=['time', 'blah'], \\\n",
    "                         delim_whitespace=False\n",
    "                     )\n",
    "\n",
    "ge_data = ge_data.sort_values(by='time')\n",
    "\n",
    "print (ge_data.head(10))\n",
    "\n",
    "t = np.asarray(ge_data[\"time\"], dtype=np.float32)\n",
    "\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b041ac-58e8-42c1-9136-e62f40f56244",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t=np.min(t)\n",
    "\n",
    "#construct histogram from our data, every bin is roughly 12 hours\n",
    "counts, bins = np.histogram(t-min_t,bins=72)\n",
    "thing = (bins[:-1]+bins[1:])/2\n",
    "error1 = [0.00,0.37,0.74,1.10,2.34,2.75,3.82,4.25,5.30,6.33,6.78,7.81,8.83,9.28]\n",
    "error2 = [1.29,2.75,4.25,5.30,6.78,7.81,9.28,10.30,11.32,12.79,13.81,14.82,16.29,17.30]\n",
    "ntot = counts\n",
    "ntot_plus = np.zeros(np.shape(ntot))\n",
    "ntot_minus = np.zeros(np.shape(ntot))\n",
    "for i,ncount in enumerate(ntot):\n",
    "    if ncount<=20:\n",
    "        ntot_plus[i] = error2[ncount]-ncount\n",
    "        ntot_minus[i] = ncount-error1[ncount]\n",
    "    else:\n",
    "        ntot_plus[i] = np.sqrt(ncount)\n",
    "        ntot_minus[i] = np.sqrt(ncount)\n",
    "\n",
    "#probabilities = np.array([poissant_distribution(n, 2) for n in counts]) i don't know what i was doing here\n",
    "\n",
    "#optimal_lambda = maximize_distribution(counts, probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63dd6211-720c-4cec-9ca9-8256216d50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  9  5  6  5  7  6  1  2  4  4  5  5  5  6  2  3  3  0  3  3  5  5  4\n",
      "  3  4  2  3  1  3  4  0  3  1  3  4  2  3  1  2  2  1  2  2  1  2  1  1\n",
      "  3  2  1  0  0  1  1  1  1  1  1  2  1  2  0  1  0  2  1  1  1  1  1  2]\n"
     ]
    }
   ],
   "source": [
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412f8596-283b-4eb4-bf55-eacf22ccaaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10993981418158977, 0.1317556400094152, 0.17546736976780875, 0.16062314091249244, 0.17546736976780875, 0.14900277966571845, 0.16062314091249244, 0.3678794411714423, 0.2706705664624776, 0.1953668145629145, 0.1953668145629145, 0.17546736976780875, 0.17546736976780875, 0.17546736976780875, 0.16062314091249244, 0.2706705664624776, 0.2240418073508977, 0.2240418073508977, 4.540199096288481e-05, 0.2240418073508977, 0.2240418073508977, 0.17546736976780875, 0.17546736976780875, 0.1953668145629145, 0.2240418073508977, 0.1953668145629145, 0.2706705664624776, 0.2240418073508977, 0.3678794411714423, 0.2240418073508977, 0.1953668145629145, 4.540199096288481e-05, 0.2240418073508977, 0.3678794411714423, 0.2240418073508977, 0.1953668145629145, 0.2706705664624776, 0.2240418073508977, 0.3678794411714423, 0.2706705664624776, 0.2706705664624776, 0.3678794411714423, 0.2706705664624776, 0.2706705664624776, 0.3678794411714423, 0.2706705664624776, 0.3678794411714423, 0.3678794411714423, 0.2240418073508977, 0.2706705664624776, 0.3678794411714423, 4.540199096288481e-05, 4.540199096288481e-05, 0.3678794411714423, 0.3678794411714423, 0.3678794411714423, 0.3678794411714423, 0.3678794411714423, 0.3678794411714423, 0.2706705664624776, 0.3678794411714423, 0.2706705664624776, 4.540199096288481e-05, 0.3678794411714423, 4.540199096288481e-05, 0.2706705664624776, 0.3678794411714423, 0.3678794411714423, 0.3678794411714423, 0.3678794411714423, 0.3678794411714423, 0.2706705664624776]\n"
     ]
    }
   ],
   "source": [
    "#initializing the array of optimal lambdas\n",
    "lambda_array = []\n",
    "for i in range(len(counts)):\n",
    "    result=maximize_distribution(counts[i])\n",
    "    lambda_array.extend(result)\n",
    "# \n",
    "prob_array = []\n",
    "for i in range(len(lambda_array)):\n",
    "    result=poissant_distribution(counts[i], lambda_array[i])\n",
    "    prob_array.extend([result])\n",
    "\n",
    "print(prob_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2e0ccf-15a8-4eef-a6f9-e8889dc7fa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.99999635]\n"
     ]
    }
   ],
   "source": [
    "#nevermind all this stuff but will be useful when we actually do the model function\n",
    "# some function parameters can be initialized as constants?\n",
    "#x = np.linspace(0,926,num=100) #i cant remember why we chose 926, workedwell for the other plots\n",
    "#print (function(x,926,271.2,1))\n",
    "#alpha = 274.32 #half life of germ 71 in hours\n",
    "#tstop = 1440 #hours\n",
    "\n",
    "#print(len(counts))\n",
    "#print(len(prob_array))\n",
    "\n",
    "counts1=np.asarray(counts)\n",
    "prob1=np.asarray(prob_array)\n",
    "# Model function is the poissant distribution\n",
    "def likelihood_func(theta, n): \n",
    "    lambda_val = theta\n",
    "    model = (np.exp(-1*lambda_val)*(lambda_val)**n)/np.math.factorial(n)\n",
    "    return model\n",
    "\n",
    "lambda_true = 5.0\n",
    "np.random.seed(69)\n",
    "nll = lambda *args: -likelihood_func(*args)\n",
    "initial = np.asarray([5]) \n",
    "soln = scipy.optimize.minimize(nll, initial, args=(counts1[1])) #I think it has a problem with the size of the arrays in the input of the likelihood function??\n",
    "lambda_val_ml = soln.x\n",
    "print(soln.x)\n",
    "#idk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d848655-4e82-42bd-be35-ce32ca63f485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 1\n",
      "8.262944390310165e-161\n",
      "hi1\n",
      "hi2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 322/5000 [00:00<00:02, 1619.96it/s]/var/folders/3s/rw_tcb5d5nb73w4p_52qbr640000gn/T/ipykernel_66269/3525401330.py:16: RuntimeWarning: overflow encountered in power\n",
      "  model = (np.exp(-1*lambda_val)*(lambda_val)**n)/np.math.factorial(n)\n",
      "  9%|▊         | 435/5000 [00:00<00:02, 1608.14it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Probability function returned NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m sampler \u001b[38;5;241m=\u001b[39m emcee\u001b[38;5;241m.\u001b[39mEnsembleSampler(\n\u001b[1;32m     21\u001b[0m     nwalkers, ndim, prob, args\u001b[38;5;241m=\u001b[39m(bin1cnts)\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mcmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;\n\u001b[1;32m     26\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m), sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m samples \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39mget_chain()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fano_pub_new/lib/python3.8/site-packages/emcee/ensemble.py:384\u001b[0m, in \u001b[0;36mEnsembleSampler.run_mcmc\u001b[0;34m(self, initial_state, nsteps, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_previous_state\n\u001b[1;32m    383\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(initial_state, iterations\u001b[38;5;241m=\u001b[39mnsteps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# Store so that the ``initial_state=None`` case will work\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fano_pub_new/lib/python3.8/site-packages/emcee/ensemble.py:343\u001b[0m, in \u001b[0;36mEnsembleSampler.sample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress)\u001b[0m\n\u001b[1;32m    340\u001b[0m move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_moves, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights)\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Propose\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m state, accepted \u001b[38;5;241m=\u001b[39m \u001b[43mmove\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m state\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tune:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fano_pub_new/lib/python3.8/site-packages/emcee/moves/red_blue.py:93\u001b[0m, in \u001b[0;36mRedBlueMove.propose\u001b[0;34m(self, model, state)\u001b[0m\n\u001b[1;32m     90\u001b[0m q, factors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_proposal(s, c, model\u001b[38;5;241m.\u001b[39mrandom)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Compute the lnprobs of the proposed position.\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m new_log_probs, new_blobs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_log_prob_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Loop over the walkers and update them accordingly.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (j, f, nlp) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mzip\u001b[39m(all_inds[S1], factors, new_log_probs)\n\u001b[1;32m     98\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fano_pub_new/lib/python3.8/site-packages/emcee/ensemble.py:456\u001b[0m, in \u001b[0;36mEnsembleSampler.compute_log_prob\u001b[0;34m(self, coords)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# Check for log_prob returning NaN.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(log_prob)):\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbability function returned NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_prob, blob\n",
      "\u001b[0;31mValueError\u001b[0m: Probability function returned NaN"
     ]
    }
   ],
   "source": [
    "def prior(theta): #this sets the prior conditions of our parameters\n",
    "    lambda_val = theta\n",
    "    if lambda_val>0:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def prob(theta, n):\n",
    "    lp = prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf \n",
    "    return lp + likelihood_func(theta, n)\n",
    "\n",
    "bin1cnts=np.asarray([counts1[0]])\n",
    "\n",
    "pos = soln.x + 1e-4 * np.random.randn(32, 1)\n",
    "nwalkers, ndim = pos.shape\n",
    "print(nwalkers, ndim)\n",
    "print(prob(5.0,150))\n",
    "print(\"hi1\")\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers, ndim, prob, args=(bin1cnts)\n",
    ")\n",
    "print(\"hi2\")\n",
    "sampler.run_mcmc(pos, 5000, progress=True);\n",
    "\n",
    "fig, axes = plt.subplots(3, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "labels = [\"lambda\"]\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "\n",
    "#autocorrelation stuffs\n",
    "tau = sampler.get_autocorr_time()\n",
    "print(tau)\n",
    "\n",
    "flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\n",
    "print(flat_samples.shape)\n",
    "\n",
    "fig = corner.corner(\n",
    "    flat_samples, labels=labels, truths=[m_true, b_true, np.log(f_true)]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e1ebb-7c9e-4335-8921-455176f6bac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fano_pub_new)",
   "language": "python",
   "name": "fano_pub_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
