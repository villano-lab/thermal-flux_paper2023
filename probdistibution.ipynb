{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87834266-3e9f-45f4-ab70-2550fee3fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: [12.99900562]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import corner\n",
    "import scipy\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "np.seterr(invalid='ignore')\n",
    "\n",
    "\n",
    "#def negPoissontDist(n, lambda_val):\n",
    " #   return -np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n)\n",
    "\n",
    "#def maximize(n):\n",
    " #   result = scipy.optimize.minimize(negPoissontDist, x0=[10], args=(n,))\n",
    "  #return result\n",
    "\n",
    "\n",
    "#This function gives the probability of getting n counts for a given bin\n",
    "def poissant_distribution(n, lambda_val):\n",
    "    return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
    "\n",
    "#This is just so we can use the minimize function from scipy\n",
    "def negative_probability_distribution(lambda_val, n):\n",
    "    return -poissant_distribution(n, lambda_val)\n",
    "\n",
    "#This will find the lambda that gives the highest probability of getting a given n, n would be our measured counts per bin\n",
    "def maximize_distribution(n):\n",
    "    result = scipy.optimize.minimize(negative_probability_distribution, x0=[10], args=(n,))\n",
    "    return result.x\n",
    "\n",
    "fixed_n = 13\n",
    "\n",
    "optimal_lambda = maximize_distribution(fixed_n)\n",
    "print(f\"Lambda: {optimal_lambda}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3cb98c7-c7e0-4d81-8548-ed1429babf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        time    blah\n",
      "9   506.1574  5.2894\n",
      "5   507.4013  5.9058\n",
      "8   509.4632  5.6750\n",
      "10  509.8995  5.2232\n",
      "13  510.0812  5.0349\n",
      "3   512.5145  6.3243\n",
      "19  512.7067  4.2205\n",
      "12  513.7324  5.0628\n",
      "14  513.8779  4.9122\n",
      "4   514.5219  6.1499\n",
      "[ 506.1574  507.4013  509.4632  509.8995  510.0812  512.5145  512.7067\n",
      "  513.7324  513.8779  514.5219  516.8201  517.7107  518.5185  519.2819\n",
      "  519.8351  524.4211  525.2859  525.2859  526.9375  528.7008  529.4175\n",
      "  530.1161  534.9125  535.2761  536.9121  537.7742  543.2328  550.717\n",
      "  551.226   553.132   553.3139  553.7683  554.0956  557.6922  558.5466\n",
      "  565.1764  566.9474  567.3552  571.5335  574.8757  576.3014  578.0828\n",
      "  578.1919  580.6901  583.0324  584.7126  587.0472  593.4147  593.986\n",
      "  594.7132  596.1207  602.9245  616.2568  616.7476  623.1592  623.5592\n",
      "  627.683   627.9011  637.3381  637.8289  638.3016  638.3275  648.4008\n",
      "  651.4703  651.517   652.3974  652.5064  660.6087  661.3799  661.4708\n",
      "  665.4129  670.0093  674.8498  676.0211  678.1193  680.363   683.178\n",
      "  687.8277  690.4077  690.9167  694.8951  696.8194  698.8008  709.4272\n",
      "  710.0634  712.5694  721.861   724.5773  725.0681  734.5129  735.8944\n",
      "  752.5689  753.0597  756.8927  768.5994  770.2354  772.0247  780.9254\n",
      "  784.5351  784.5403  784.626   788.0499  789.7717  790.3884  792.6737\n",
      "  794.7719  801.5653  804.2089  805.5385  807.7692  809.839   816.0662\n",
      "  823.4777  827.1703  830.1387  832.3434  832.5551  839.721   841.3675\n",
      "  847.8181  853.5546  853.9     860.0117  876.7835  884.5262  886.083\n",
      "  888.8162  894.0917  895.0175  895.4213  901.3032  919.145   924.2362\n",
      "  925.0892  930.8699  952.5186  953.6678  955.4336  958.5953  959.9665\n",
      "  966.047   966.8195  978.0692  981.1192  988.5463  993.1778  993.7711\n",
      "  997.9729 1008.572  1010.5846 1022.3913 1030.2712 1045.506  1046.2968\n",
      " 1046.7784 1066.0433 1071.4344 1076.9424 1087.1377 1095.6112 1109.2084\n",
      " 1110.499  1123.9365 1127.6812 1134.2124 1138.4453 1147.1006 1157.1271\n",
      " 1190.3904 1209.1268 1213.3129 1231.4962 1244.195  1263.1313 1268.3276\n",
      " 1276.3285 1279.7616 1298.9628 1298.9991 1324.7574 1341.9045 1348.0826\n",
      " 1360.0256 1376.1833 1383.8856 1399.0356 1416.2997 1421.1974 1431.6056]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "\n",
    "#importing and sorting data\n",
    "ge_data = pds.read_csv(\"SuperCDMS/PhysRevD.99.062001-data/MarchAprilFinal.txt\", skiprows=1, \\\n",
    "                         names=['time', 'blah'], \\\n",
    "                         delim_whitespace=False\n",
    "                     )\n",
    "\n",
    "ge_data = ge_data.sort_values(by='time')\n",
    "\n",
    "print (ge_data.head(10))\n",
    "\n",
    "t = np.asarray(ge_data[\"time\"], dtype=np.float32)\n",
    "\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b041ac-58e8-42c1-9136-e62f40f56244",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_t=np.min(t)\n",
    "\n",
    "#construct histogram from our data, every bin is roughly 12 hours\n",
    "counts, bins = np.histogram(t-min_t,bins=72)\n",
    "thing = (bins[:-1]+bins[1:])/2\n",
    "error1 = [0.00,0.37,0.74,1.10,2.34,2.75,3.82,4.25,5.30,6.33,6.78,7.81,8.83,9.28]\n",
    "error2 = [1.29,2.75,4.25,5.30,6.78,7.81,9.28,10.30,11.32,12.79,13.81,14.82,16.29,17.30]\n",
    "ntot = counts\n",
    "ntot_plus = np.zeros(np.shape(ntot))\n",
    "ntot_minus = np.zeros(np.shape(ntot))\n",
    "for i,ncount in enumerate(ntot):\n",
    "    if ncount<=20:\n",
    "        ntot_plus[i] = error2[ncount]-ncount\n",
    "        ntot_minus[i] = ncount-error1[ncount]\n",
    "    else:\n",
    "        ntot_plus[i] = np.sqrt(ncount)\n",
    "        ntot_minus[i] = np.sqrt(ncount)\n",
    "\n",
    "#probabilities = np.array([poissant_distribution(n, 2) for n in counts]) i don't know what i was doing here\n",
    "\n",
    "#optimal_lambda = maximize_distribution(counts, probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63dd6211-720c-4cec-9ca9-8256216d50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  9  5  6  5  7  6  1  2  4  4  5  5  5  6  2  3  3  0  3  3  5  5  4\n",
      "  3  4  2  3  1  3  4  0  3  1  3  4  2  3  1  2  2  1  2  2  1  2  1  1\n",
      "  3  2  1  0  0  1  1  1  1  1  1  2  1  2  0  1  0  2  1  1  1  1  1  2]\n"
     ]
    }
   ],
   "source": [
    "print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412f8596-283b-4eb4-bf55-eacf22ccaaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in power\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in power\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in power\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n",
      "C:\\Users\\cecih\\AppData\\Local\\Temp\\ipykernel_9412\\1559133941.py:21: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-lambda_val) * (lambda_val**n) / np.math.factorial(n) #numpy gets mad at the math here but can just ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([12.99900562]), array([9.00022898]), array([5.00012877]), array([6.83768424]), array([5.00012877]), array([7.00004227]), array([6.83768424]), array([0.99999105]), array([2.00004861]), array([4.18880904]), array([4.18880904]), array([5.00012877]), array([5.00012877]), array([5.00012877]), array([6.83768424]), array([2.00004861]), array([2.99990993]), array([2.99990993]), array([9.95351047]), array([2.99990993]), array([2.99990993]), array([5.00012877]), array([5.00012877]), array([4.18880904]), array([2.99990993]), array([4.18880904]), array([2.00004861]), array([2.99990993]), array([0.99999105]), array([2.99990993]), array([4.18880904]), array([9.95351047]), array([2.99990993]), array([0.99999105]), array([2.99990993]), array([4.18880904]), array([2.00004861]), array([2.99990993]), array([0.99999105]), array([2.00004861]), array([2.00004861]), array([0.99999105]), array([2.00004861]), array([2.00004861]), array([0.99999105]), array([2.00004861]), array([0.99999105]), array([0.99999105]), array([2.99990993]), array([2.00004861]), array([0.99999105]), array([9.95351047]), array([9.95351047]), array([0.99999105]), array([0.99999105]), array([0.99999105]), array([0.99999105]), array([0.99999105]), array([0.99999105]), array([2.00004861]), array([0.99999105]), array([2.00004861]), array([9.95351047]), array([0.99999105]), array([9.95351047]), array([2.00004861]), array([0.99999105]), array([0.99999105]), array([0.99999105]), array([0.99999105]), array([0.99999105]), array([2.00004861])]\n"
     ]
    }
   ],
   "source": [
    "#initializing the array of optimal lambdas\n",
    "lambda_array = []\n",
    "for i in range(len(counts)):\n",
    "    result=maximize_distribution(counts[i])\n",
    "    lambda_array.append(result)\n",
    "# \n",
    "prob_array = []\n",
    "for i in range(len(lambda_array)):\n",
    "    result=poissant_distribution(counts[i], lambda_array[i])\n",
    "    prob_array.append(result)\n",
    "\n",
    "print(lambda_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2e0ccf-15a8-4eef-a6f9-e8889dc7fa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Model function is the poissant distribution\\ndef likelihood_func(n, prob, theta): \\n    lambda_val = theta\\n    model = (np.exp(-1*lambda_val)*(lambda_val)**n)/np.math.factorial(n)\\n    return model\\n\\nlambda_true = 5.0\\nnp.random.seed(69)\\nnll = lambda *args: -likelihood_func(*args)\\ninitial = np.array([lambda_true]) + 0.1 * np.random.randn(3) #u were copying the snippets from the emcee fitting reference, but the m_true etc parameters were for generating fake data, maybe use an estimate?\\nsoln = scipy.optimize.minimize(nll, initial, args=(counts, prob_array))\\nlambda_val_ml = soln.n\\n#idk\\n\\ndef prior(theta): #this sets the prior conditions of our parameters\\n    lambda_val = theta\\n    if lambda_val>0:\\n        return 0.0\\n    return -np.inf\\n\\ndef prob(theta, n):\\n    lp = prior(theta)\\n    if not np.isfinite(lp):\\n        return -np.inf \\n    return lp + likelihood_func(theta, n, prob)\\n\\npos = soln.lambda_val + 1e-4 * np.random.randn(32, 3)\\nnwalkers, ndim = pos.shape\\n\\nsampler = emcee.EnsembleSampler(\\n    nwalkers, ndim, log_probability, args=(n, P, yerr)\\n)\\n\\nsampler.run_mcmc(pos, 5000, progress=True);\\n\\nfig, axes = plt.subplots(3, figsize=(10, 7), sharex=True)\\nsamples = sampler.get_chain()\\nlabels = [\"lambda\"]\\nfor i in range(ndim):\\n    ax = axes[i]\\n    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\\n    ax.set_xlim(0, len(samples))\\n    ax.set_ylabel(labels[i])\\n    ax.yaxis.set_label_coords(-0.1, 0.5)\\n\\naxes[-1].set_xlabel(\"step number\");\\n\\n#autocorrelation stuffs\\ntau = sampler.get_autocorr_time()\\nprint(tau)\\n\\nflat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\\nprint(flat_samples.shape)\\n\\nfig = corner.corner(\\n    flat_samples, labels=labels, truths=[m_true, b_true, np.log(f_true)]\\n);\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nevermind all this stuff but will be useful when we actually do the model function\n",
    "# some function parameters can be initialized as constants?\n",
    "#x = np.linspace(0,926,num=100) #i cant remember why we chose 926, workedwell for the other plots\n",
    "#print (function(x,926,271.2,1))\n",
    "#alpha = 274.32 #half life of germ 71 in hours\n",
    "#tstop = 1440 #hours\n",
    "\n",
    "print(len(counts))\n",
    "print(len(prob_array))\n",
    "\n",
    "\"\"\"\n",
    "# Model function is the poissant distribution\n",
    "def likelihood_func(n, prob, theta): \n",
    "    lambda_val = theta\n",
    "    model = (np.exp(-1*lambda_val)*(lambda_val)**n)/np.math.factorial(n)\n",
    "    return model\n",
    "\n",
    "lambda_true = 5.0\n",
    "np.random.seed(69)\n",
    "nll = lambda *args: -likelihood_func(*args)\n",
    "initial = np.array([lambda_true]) + 0.1 * np.random.randn(3) #u were copying the snippets from the emcee fitting reference, but the m_true etc parameters were for generating fake data, maybe use an estimate?\n",
    "soln = scipy.optimize.minimize(nll, initial, args=(counts, prob_array)) #I think it has a problem with the size of the arrays in the input of the likelihood function??\n",
    "lambda_val_ml = soln.n\n",
    "#idk\n",
    "\n",
    "def prior(theta): #this sets the prior conditions of our parameters\n",
    "    lambda_val = theta\n",
    "    if lambda_val>0:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def prob(theta, n):\n",
    "    lp = prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf \n",
    "    return lp + likelihood_func(theta, n, prob)\n",
    "\n",
    "pos = soln.lambda_val + 1e-4 * np.random.randn(32, 3)\n",
    "nwalkers, ndim = pos.shape\n",
    "\n",
    "sampler = emcee.EnsembleSampler(\n",
    "    nwalkers, ndim, log_probability, args=(n, P, yerr)\n",
    ")\n",
    "\n",
    "sampler.run_mcmc(pos, 5000, progress=True);\n",
    "\n",
    "fig, axes = plt.subplots(3, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain()\n",
    "labels = [\"lambda\"]\n",
    "for i in range(ndim):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");\n",
    "\n",
    "#autocorrelation stuffs\n",
    "tau = sampler.get_autocorr_time()\n",
    "print(tau)\n",
    "\n",
    "flat_samples = sampler.get_chain(discard=100, thin=15, flat=True)\n",
    "print(flat_samples.shape)\n",
    "\n",
    "fig = corner.corner(\n",
    "    flat_samples, labels=labels, truths=[m_true, b_true, np.log(f_true)]\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d848655-4e82-42bd-be35-ce32ca63f485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
